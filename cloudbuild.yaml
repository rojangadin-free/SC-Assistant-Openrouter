steps:
  # 1. Build the Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      # This --no-cache flag is CRITICAL. It ensures we get a
      # clean build and run our new download_model.py script.
      - '--no-cache' 
      - '-t'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE_NAME}:$COMMIT_SHA'
      - '.'
    id: 'Build'
  
  # 2. Push the built image to your Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE_NAME}:$COMMIT_SHA'
    id: 'Push'

  # 3. Deploy the image to Cloud Run
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'run'
      - 'deploy'
      - '${_SERVICE_NAME}'
      - '--image=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE_NAME}:$COMMIT_SHA'
      - '--region=${_REGION}'
      - '--platform=managed'
      - '--allow-unauthenticated'
      
      # We are increasing the memory from 2Gi to 6Gi
      - '--memory=8Gi'
      - '--cpu=2'
      
      - '--set-secrets=PINECONE_API_KEY=PINECONE_API_KEY:latest,OPENROUTER_API_KEY=OPENROUTER_API_KEY:latest,AWS_REGION=AWS_REGION:latest,COGNITO_USER_POOL_ID=COGNITO_USER_POOL_ID:latest,COGNITO_CLIENT_ID=COGNITO_CLIENT_ID:latest,AWS_ACCESS_KEY_ID=AWS_ACCESS_KEY_ID:latest,AWS_SECRET_ACCESS_KEY=AWS_SECRET_ACCESS_KEY:latest,FLASK_SECRET_KEY=FLASK_SECRET_KEY:latest'
    id: 'Deploy'

images:
  - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE_NAME}:$COMMIT_SHA'

substitutions:
  _REGION: 'us-east4'
  _REPOSITORY: 'sc-assistant-repo'
  _IMAGE_NAME: 'sc-assistant-image'
  _SERVICE_NAME: 'sc-assistant'

timeout: '3600s' # 60 minutes

options:
  machineType: 'E2_HIGHCPU_8'
  defaultLogsBucketBehavior: 'REGIONAL_USER_OWNED_BUCKET'